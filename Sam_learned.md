### What I've Learned from this Distributed Capsule Networks Project

This quarter I got the opportunity to learn about the newest type of neural network, capsule networks. Having an interest in machine learning, I had never heard of capsule networks before and was super excited to be able to dedicate a quarter-long project to exploring their capabilities and learning more about them.
At the beginning of the quarter, I was able to find numerous blog posts that helped me better understand capsule networks (as I'm sure many of us have experienced, some papers can be fairly difficult to process and comprehend - Hinton's paper was no exception). I'd like to acknowledge Max Pechyonkin's capsule network blog series (https://medium.com/ai%C2%B3-theory-practice-business/understanding-hintons-capsule-networks-part-i-intuition-b4b559d1159b), who I believe did a proficient job breaking down capsule networks and who I credit with helping me understand them.

Capsule networks aim to mainly solve convolutional neural networks' issue of handling viewpoint invariance. That is, convolutional neural networks use max pooling to achieve viewpoint invariance, and therefore loses important information regarding the spatial relationships between features. So although convolutional neural networks are able to keep track of where features lie in an image, they can't figure out how different features are related to each other. Capsule networks aim to solve this problem using "capsules", which are able to encode all of the information regarding the state of the feature(s) they are recognizing into vector form. With this approach, capsule networks are able to encode the probability of a feature being detected as the length of the feature's vector, and the state of the feature (e.g., orientation, etc.) is encoded as the vector's direction. So when a capsule network detects a feature in an image, and that feature is moved across the image, the vector will rotate with the feature but its length will remain fixed because it knows the feature it is detecting. This achieves equivariance, meaning that the outputs of the neurons in the network change when the features move or change in respect to the image it's in (remember that convolutional neural networks do not do this). Capsule networks also achieve invariance in the way that the probability of a feature being detected remains constant as the feature travels to different parts of an image, which is a huge improvement to convolutional neural networks' max pooling method. 

Since capsule networks are so new, there has only been so much work done in regards to replicating and improving Hinton's results. The objective of our research project was to investigate distributing the training of capsule networks to decrease the total runtime while maintaining accuracy. We ran experiments using Tensorflow and Horovod, increasing the number of machines and seeing a dramatic increase in training time - from 610 seconds per epoch using one machine down to 60 seconds per epoch using 15 machines - while also achieving the same accuracy of the original implemetation.

The complete results of our experiments will be available soon, in the form of a conference-worthy paper. Stay tuned! 
